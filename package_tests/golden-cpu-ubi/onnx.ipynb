{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2de62032",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1: Importing onnx, numpy, and os passed.\n",
      "Step 2: Creating a simple ONNX model passed.\n",
      "Step 3: Model validation passed.\n",
      "Step 4: Model information:\n",
      "graph simple-addition-graph (\n",
      "  %input[FLOAT, 1x3x224x224]\n",
      ") {\n",
      "  %output = Add(%input, %input)\n",
      "  return %output\n",
      "}\n",
      "Step 4: Printing model information passed.\n",
      "Step 5: Performing inference using ONNX Runtime passed.\n",
      "Step 6: Saving the ONNX model passed.\n",
      "All extensive tests for the 'onnx' package completed successfully.\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Import the package\n",
    "try:\n",
    "    import onnx\n",
    "    from onnx import helper, TensorProto, checker\n",
    "    import numpy as np\n",
    "    import os\n",
    "    print(\"Step 1: Importing onnx, numpy, and os passed.\")\n",
    "except ImportError:\n",
    "    print(\"Step 1 failed: 'onnx', 'numpy', or 'os' is not installed.\")\n",
    "    sys.exit(1)\n",
    "except Exception as e:\n",
    "    print(f\"Step 1 failed with an unexpected error: {str(e)}\")\n",
    "    sys.exit(1)\n",
    "\n",
    "# Step 2: Create a simple ONNX model\n",
    "try:\n",
    "    # Define the model input (1x3x224x224 tensor)\n",
    "    input_tensor = helper.make_tensor_value_info('input', TensorProto.FLOAT, [1, 3, 224, 224])\n",
    "\n",
    "    # Define the model output (1x3x224x224 tensor)\n",
    "    output_tensor = helper.make_tensor_value_info('output', TensorProto.FLOAT, [1, 3, 224, 224])\n",
    "\n",
    "    # Create a simple node that performs an element-wise addition of the input with itself\n",
    "    add_node = helper.make_node(\n",
    "        'Add',  # Operator name\n",
    "        ['input', 'input'],  # Inputs\n",
    "        ['output']  # Outputs\n",
    "    )\n",
    "\n",
    "    # Create the graph\n",
    "    graph_def = helper.make_graph(\n",
    "        [add_node],\n",
    "        'simple-addition-graph',  # Graph name\n",
    "        [input_tensor],  # Inputs\n",
    "        [output_tensor]  # Outputs\n",
    "    )\n",
    "\n",
    "    # Create the model\n",
    "    model_def = helper.make_model(graph_def, producer_name='onnx-example')\n",
    "    \n",
    "    print(\"Step 2: Creating a simple ONNX model passed.\")\n",
    "except Exception as e:\n",
    "    print(f\"Step 2 failed: {str(e)}\")\n",
    "    sys.exit(1)\n",
    "\n",
    "# Step 3: Validate the created ONNX model\n",
    "try:\n",
    "    checker.check_model(model_def)\n",
    "    print(\"Step 3: Model validation passed.\")\n",
    "except onnx.checker.ValidationError as e:\n",
    "    print(f\"Step 3 failed: Model validation error - {str(e)}\")\n",
    "    sys.exit(1)\n",
    "except Exception as e:\n",
    "    print(f\"Step 3 failed: {str(e)}\")\n",
    "    sys.exit(1)\n",
    "\n",
    "# Step 4: Print model information\n",
    "try:\n",
    "    model_info = onnx.helper.printable_graph(model_def.graph)\n",
    "    print(\"Step 4: Model information:\")\n",
    "    print(model_info)\n",
    "    print(\"Step 4: Printing model information passed.\")\n",
    "except Exception as e:\n",
    "    print(f\"Step 4 failed: {str(e)}\")\n",
    "    sys.exit(1)\n",
    "\n",
    "# Step 5: Perform inference using the ONNX model with ONNX Runtime\n",
    "try:\n",
    "    import onnxruntime as ort\n",
    "    \n",
    "    # Save the model to a file to use with ONNX Runtime\n",
    "    onnx.save(model_def, 'simple_model.onnx')\n",
    "    \n",
    "    # Create an ONNX Runtime session\n",
    "    session = ort.InferenceSession('simple_model.onnx')\n",
    "    \n",
    "    # Generate a dummy input matching the model's input shape\n",
    "    dummy_input = np.random.randn(1, 3, 224, 224).astype(np.float32)\n",
    "    \n",
    "    # Perform inference\n",
    "    input_name = session.get_inputs()[0].name\n",
    "    output_name = session.get_outputs()[0].name\n",
    "    result = session.run([output_name], {input_name: dummy_input})\n",
    "    \n",
    "    assert result is not None, \"Inference failed, no output received.\"\n",
    "    assert np.allclose(result, dummy_input + dummy_input), \"Inference result is not as expected.\"\n",
    "    print(\"Step 5: Performing inference using ONNX Runtime passed.\")\n",
    "except ImportError:\n",
    "    print(\"Step 5 failed: 'onnxruntime' is not installed.\")\n",
    "    sys.exit(1)\n",
    "except Exception as e:\n",
    "    print(f\"Step 5 failed: {str(e)}\")\n",
    "    sys.exit(1)\n",
    "\n",
    "# Step 6: Save the ONNX model to a new file\n",
    "try:\n",
    "    onnx.save(model_def, 'saved_simple_model.onnx')\n",
    "    assert os.path.exists('saved_simple_model.onnx'), \"Model save failed, file not created.\"\n",
    "    print(\"Step 6: Saving the ONNX model passed.\")\n",
    "except Exception as e:\n",
    "    print(f\"Step 6 failed: {str(e)}\")\n",
    "    sys.exit(1)\n",
    "\n",
    "# Final Confirmation\n",
    "print(\"All extensive tests for the 'onnx' package completed successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d542586-0e0c-4bfd-9299-dc8bfb447eef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
