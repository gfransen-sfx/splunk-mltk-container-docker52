{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ce6ef6db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1: Importing modules passed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.\n",
      "Perhaps you already have a cluster running?\n",
      "Hosting the HTTP server on port 33245 instead\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/site-packages/dask_expr/_collection.py:5983: UserWarning: dask_expr does not support the DataFrameIOFunction protocol for column projection. To enable column projection, please ensure that the signature of `func` includes a `columns=` keyword argument instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Partition sizes: 0     29\n",
      "1     31\n",
      "2     30\n",
      "3     31\n",
      "4     30\n",
      "5     31\n",
      "6     31\n",
      "7     30\n",
      "8     31\n",
      "9     30\n",
      "10    31\n",
      "dtype: int64\n",
      "Repartitioned sizes: 0     20\n",
      "1     21\n",
      "2     21\n",
      "3     21\n",
      "4     21\n",
      "5     21\n",
      "6     21\n",
      "7     21\n",
      "8     21\n",
      "9     22\n",
      "10    20\n",
      "11    21\n",
      "12    22\n",
      "13    20\n",
      "14    21\n",
      "15    21\n",
      "dtype: int64\n",
      "Step 2: Initialization passed.\n",
      "X_dask shape: (335, 2), y_dask shape: (335,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[12:26:43] Task [xgboost.dask-0]:tcp://127.0.0.1:45305 got rank 0\n",
      "[12:26:43] Task [xgboost.dask-2]:tcp://127.0.0.1:40773 got rank 2\n",
      "[12:26:43] Task [xgboost.dask-1]:tcp://127.0.0.1:33763 got rank 1\n",
      "[12:26:43] Task [xgboost.dask-3]:tcp://127.0.0.1:44953 got rank 3\n",
      "[12:26:43] Task [xgboost.dask-1]:tcp://127.0.0.1:33763 got rank 0\n",
      "[12:26:43] WARNING: /workspace/src/common/error_msg.cc:52: Empty dataset at worker: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 3: Basic operations passed.\n",
      "All tests completed successfully.\n"
     ]
    }
   ],
   "source": [
    "# Disable dask_expr by setting an environment variable\n",
    "import os\n",
    "os.environ['DASK_EXPRESSION'] = '0'\n",
    "\n",
    "# Test for Dask with XGBoost integration\n",
    "\n",
    "# Step 1: Import necessary modules\n",
    "try:\n",
    "    from dask import array as da\n",
    "    import dask.dataframe as dd\n",
    "    import dask.distributed\n",
    "    import xgboost as xgb\n",
    "    from xgboost.dask import DaskDMatrix, train as dask_xgboost_train\n",
    "    from dask.dataframe.utils import make_meta\n",
    "    print(\"Step 1: Importing modules passed.\")\n",
    "except Exception as e:\n",
    "    print(f\"Step 1 failed: {str(e)}\")\n",
    "    raise e\n",
    "\n",
    "# Step 2: Create or initialize necessary objects\n",
    "try:\n",
    "    # Set up a Dask client\n",
    "    client = dask.distributed.Client()\n",
    "\n",
    "    # Create a small Dask DataFrame\n",
    "    df = dd.demo.make_timeseries(start='2000', end='2001', freq='1D', \n",
    "                                 partition_freq='1ME', seed=42)\n",
    "\n",
    "    # Define metadata explicitly\n",
    "    meta = make_meta({'x': 'f8', 'y': 'f8', 'id': 'i8'})\n",
    "\n",
    "    # Use map_partitions with an explicit columns= argument and defined meta\n",
    "    def select_columns(df, columns=None):\n",
    "        return df[columns]\n",
    "\n",
    "    df = df.map_partitions(select_columns, columns=['x', 'y', 'id'], meta=meta)\n",
    "\n",
    "    # Check initial partition sizes\n",
    "    initial_partition_sizes = df.map_partitions(len).compute()\n",
    "    print(\"Initial Partition sizes:\", initial_partition_sizes)\n",
    "\n",
    "    # Repartition the DataFrame to ensure better distribution\n",
    "    df = df.repartition(npartitions=16)\n",
    "\n",
    "    # Check repartitioned sizes\n",
    "    repartitioned_sizes = df.map_partitions(len).compute()\n",
    "    print(\"Repartitioned sizes:\", repartitioned_sizes)\n",
    "\n",
    "    print(\"Step 2: Initialization passed.\")\n",
    "except Exception as e:\n",
    "    print(f\"Step 2 failed: {str(e)}\")\n",
    "    raise e\n",
    "\n",
    "# Step 3: Perform basic operations\n",
    "try:\n",
    "    # Define features and labels\n",
    "    X_dask = df[['x', 'y']].to_dask_array(lengths=True)\n",
    "    y_dask = df['id'].to_dask_array(lengths=True)\n",
    "\n",
    "    # Verify array shapes\n",
    "    print(f\"X_dask shape: {X_dask.shape}, y_dask shape: {y_dask.shape}\")\n",
    "\n",
    "    # Train a Dask-XGBoost model\n",
    "    params = {'objective': 'reg:squarederror', 'max_depth': 5}\n",
    "    dtrain = DaskDMatrix(client, X_dask, y_dask)\n",
    "    output = dask_xgboost_train(client, params, dtrain, num_boost_round=10)\n",
    "\n",
    "    print(\"Step 3: Basic operations passed.\")\n",
    "except Exception as e:\n",
    "    print(f\"Step 3 failed: {str(e)}\")\n",
    "    raise e\n",
    "\n",
    "# Step 4: Error handling and edge cases\n",
    "try:\n",
    "    try:\n",
    "        # Attempt to train on empty data\n",
    "        empty_X = da.empty((0, 2))\n",
    "        empty_y = da.empty(0)\n",
    "        empty_dtrain = DaskDMatrix(client, empty_X, empty_y)\n",
    "        output = dask_xgboost_train(client, params, empty_dtrain, num_boost_round=10)\n",
    "    except ValueError as e:\n",
    "        print(f\"Step 4: Correctly handled error: {str(e)}\")\n",
    "except Exception as e:\n",
    "    print(f\"Step 4 failed: {str(e)}\")\n",
    "    raise e\n",
    "\n",
    "# Step 5: Final Confirmation\n",
    "print(\"All tests completed successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6765ead0-cf2b-41c4-a887-1c8ea44d8823",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
