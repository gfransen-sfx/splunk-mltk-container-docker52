{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning Toolkit for Splunk - Robust Random Cut Forest for Anomaly Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains a barebone example workflow how to work on custom containerized code that seamlessly interfaces with the Deep Learning Toolkit for Splunk."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: By default every time you save this notebook the cells are exported into a python module which is then invoked by Splunk MLTK commands like <code> | fit ... | apply ... | summary </code>. Please read the Model Development Guide in the Deep Learning Toolkit app for more information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 0 - import libraries\n",
    "At stage 0 we define all imports necessary to run our subsequent code depending on various libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "deletable": false,
    "name": "mltkc_import"
   },
   "outputs": [],
   "source": [
    "# this definition exposes all python module imports that should be available in all subsequent commands\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import rrcf as rcf\n",
    "# ...\n",
    "# global constants\n",
    "MODEL_DIRECTORY = \"/srv/app/model/data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numpy version: 1.19.2\n",
      "pandas version: 1.1.3\n",
      "rrcf version: 0.4.3\n"
     ]
    }
   ],
   "source": [
    "# THIS CELL IS NOT EXPORTED - free notebook cell for testing or development purposes\n",
    "print(\"numpy version: \" + np.__version__)\n",
    "print(\"pandas version: \" + pd.__version__)\n",
    "print(\"rrcf version: \" + rcf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 1 - get a data sample from Splunk\n",
    "In Splunk run a search to pipe a dataset into your notebook environment. Note: mode=stage is used in the | fit command to do this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| inputlookup app_usage.csv<br>\n",
    "| table _time OTHER Recruiting<br>\n",
    "| fit MLTKContainer mode=stage algo=random_cut_forest OTHER from Recruiting threshold=0.1 into app:random_cut_forest<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After you run this search your data set sample is available as a csv inside the container to develop your model. The name is taken from the into keyword (\"barebone_model\" in the example above) or set to \"default\" if no into keyword is present. This step is intended to work with a subset of your data to create your custom model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "name": "mltkc_stage"
   },
   "outputs": [],
   "source": [
    "# this cell is not executed from MLTK and should only be used for staging data into the notebook environment\n",
    "def stage(name):\n",
    "    with open(\"data/\"+name+\".csv\", 'r') as f:\n",
    "        df = pd.read_csv(f)\n",
    "    with open(\"data/\"+name+\".json\", 'r') as f:\n",
    "        param = json.load(f)\n",
    "    return df, param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             OTHER   Recruiting\n",
      "count    91.000000    91.000000\n",
      "mean    418.912088   229.890110\n",
      "std     361.962234   244.979113\n",
      "min      24.000000     7.000000\n",
      "25%     174.000000    42.500000\n",
      "50%     380.000000   247.000000\n",
      "75%     482.000000   305.500000\n",
      "max    2102.000000  2168.000000\n",
      "   OTHER  Recruiting\n",
      "0    144          33\n",
      "1    188          30\n",
      "2   1175         297\n",
      "3   1475         308\n",
      "4   1111         305\n",
      "{'options': {'params': {'mode': 'stage', 'algo': 'random_cut_forest', 'threshold': '0.1'}, 'args': ['OTHER', 'Recruiting'], 'target_variable': ['OTHER'], 'feature_variables': ['Recruiting'], 'model_name': 'random_cut_forest', 'algo_name': 'MLTKContainer', 'mlspl_limits': {'disabled': False, 'handle_new_cat': 'default', 'max_distinct_cat_values': '10000', 'max_distinct_cat_values_for_classifiers': '10000', 'max_distinct_cat_values_for_scoring': '10000', 'max_fit_time': '6000', 'max_inputs': '100000000', 'max_memory_usage_mb': '4000', 'max_model_size_mb': '150', 'max_score_time': '6000', 'streaming_apply': '0', 'use_sampling': '1'}, 'kfold_cv': None}, 'feature_variables': ['Recruiting'], 'target_variables': ['OTHER']}\n"
     ]
    }
   ],
   "source": [
    "# THIS CELL IS NOT EXPORTED - free notebook cell for testing or development purposes\n",
    "df, param = stage(\"random_cut_forest\")\n",
    "print(df.describe())\n",
    "print(df.head())\n",
    "print(param)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 2 - create and initialize a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": false,
    "name": "mltkc_init"
   },
   "outputs": [],
   "source": [
    "# Create the random cut forest from the source data\n",
    "def init(df,param):\n",
    "    # Set model parameters\n",
    "    features=len(df)\n",
    "    num_trees=15\n",
    "    tree_size=30\n",
    "    sample_size_range=(features // tree_size, tree_size)\n",
    "    \n",
    "    if 'options' in param:\n",
    "        if 'params' in param['options']:\n",
    "            if 'num_trees' in param['options']['params']:\n",
    "                num_trees = int(param['options']['params']['num_trees'])\n",
    "            if 'tree_size' in param['options']['params']:\n",
    "                tree_size = int(param['options']['params']['tree_size'])\n",
    "    \n",
    "    # Convert data to nparray\n",
    "    variables=[]\n",
    "    \n",
    "    if 'target_variables' in param:\n",
    "        variables=param['target_variables']\n",
    "        \n",
    "    other_variables=[]\n",
    "    \n",
    "    if 'feature_variables' in param:\n",
    "        other_variables=param['feature_variables']\n",
    "\n",
    "    for item in other_variables:\n",
    "        variables.append(item)\n",
    "    \n",
    "    data=df[variables].to_numpy().astype(float)\n",
    "    \n",
    "    # Create the random cut forest\n",
    "    forest = []\n",
    "    while len(forest) < num_trees:\n",
    "        # Select random subsets of points uniformly\n",
    "        ixs = np.random.choice(features, size=sample_size_range,\n",
    "                               replace=False)\n",
    "        # Add sampled trees to forest\n",
    "        trees = [rcf.RCTree(data[ix], index_labels=ix)\n",
    "                 for ix in ixs]\n",
    "        forest.extend(trees)\n",
    "    return forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# THIS CELL IS NOT EXPORTED - free notebook cell for testing or development purposes\n",
    "model=init(df,param)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 3 - fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "deletable": false,
    "name": "mltkc_fit"
   },
   "outputs": [],
   "source": [
    "# train your model\n",
    "# returns a fit info json object and may modify the model object\n",
    "def fit(model,df,param):\n",
    "    \n",
    "    return len(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n"
     ]
    }
   ],
   "source": [
    "# THIS CELL IS NOT EXPORTED - free notebook cell for testing or development purposes\n",
    "print(fit(model,df,param))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 4 - apply the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "deletable": false,
    "name": "mltkc_apply"
   },
   "outputs": [],
   "source": [
    "# apply your model\n",
    "# returns the calculated results\n",
    "def apply(model,df,param):\n",
    "    # Calculate the collusive displacement of the points in the random trees\n",
    "    features=len(df)\n",
    "    threshold=0.01\n",
    "    \n",
    "    if 'options' in param:\n",
    "        if 'params' in param['options']:\n",
    "            if 'threshold' in param['options']['params']:\n",
    "                threshold = float(param['options']['params']['threshold'])\n",
    "    \n",
    "    avg_codisp = pd.Series(0.0, index=np.arange(features))\n",
    "    index = np.zeros(features)\n",
    "\n",
    "    for tree in model:\n",
    "        codisp = pd.Series({leaf : tree.codisp(leaf)\n",
    "                           for leaf in tree.leaves})\n",
    "\n",
    "        avg_codisp[codisp.index] += codisp\n",
    "        np.add.at(index, codisp.index.values, 1)\n",
    "    avg_codisp /= index\n",
    "    \n",
    "    # Identify outliers based on the collusive displacement values\n",
    "    threshold_percentage=int(threshold*features)\n",
    "    threshold = avg_codisp.nlargest(n=threshold_percentage).min()\n",
    "    \n",
    "    outlier=(avg_codisp >= threshold).astype(float)\n",
    "    \n",
    "    result=pd.DataFrame({'outlier':outlier,'collusive_displacement':avg_codisp})\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# THIS CELL IS NOT EXPORTED - free notebook cell for testing or development purposes\n",
    "results=apply(model,df,param)\n",
    "results['outlier'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 5 - save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "deletable": false,
    "name": "mltkc_save"
   },
   "outputs": [],
   "source": [
    "# save model to name in expected convention \"<algo_name>_<model_name>\"\n",
    "def save(model,name):\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 6 - load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "deletable": false,
    "name": "mltkc_load"
   },
   "outputs": [],
   "source": [
    "# load model from name in expected convention \"<algo_name>_<model_name>\"\n",
    "def load(name):\n",
    "    model = {}\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 7 - provide a summary of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "deletable": false,
    "name": "mltkc_summary"
   },
   "outputs": [],
   "source": [
    "# return a model summary\n",
    "def summary(model=None):\n",
    "    returns = {\"version\": {\"numpy\": np.__version__, \"pandas\": pd.__version__} }\n",
    "    return returns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End of Stages\n",
    "All subsequent cells are not tagged and can be used for further freeform code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logic: \n",
    "\n",
    "Set some basic parameters (tree size for example)\n",
    "\n",
    "Convert DF into an array\n",
    "\n",
    "Create a RRCF based on random splits of the data\n",
    "\n",
    "Calculate co-displacement based on the random cuts\n",
    "\n",
    "Return co-displacement to Splunk\n",
    "\n",
    "\n",
    "### Next steps:\n",
    "\n",
    "Save the tree\n",
    "\n",
    "Add logic to append to and re-calucate the co-disp as new data is seen\n",
    "\n",
    "### Recommendations:\n",
    "\n",
    "Scale the data\n",
    "\n",
    "Use NPR to convert high cardinatlity data points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
