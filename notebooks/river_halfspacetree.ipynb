{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning Toolkit for Splunk - Online Learning with Half Space Trees\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains an example workflow how to work on custom containerized code that seamlessly interfaces with the Deep Learning Toolkit for Splunk."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: By default every time you save this notebook the cells are exported into a python module which is then invoked by Splunk MLTK commands like <code> | fit ... | apply ... | summary </code>. Please read the Model Development Guide in the Deep Learning Toolkit app for more information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 0 - import libraries\n",
    "At stage 0 we define all imports necessary to run our subsequent code depending on various libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "name": "mltkc_import"
   },
   "outputs": [],
   "source": [
    "# this definition exposes all python module imports that should be available in all subsequent commands\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from river import anomaly\n",
    "from river import compose\n",
    "from river import datasets\n",
    "from river import metrics\n",
    "from river import preprocessing\n",
    "import pickle\n",
    "# ...\n",
    "# global constants\n",
    "MODEL_DIRECTORY = \"/srv/app/model/data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numpy version: 1.21.4\n",
      "pandas version: 1.3.4\n",
      "river version: 0.8.0\n"
     ]
    }
   ],
   "source": [
    "# THIS CELL IS NOT EXPORTED - free notebook cell for testing or development purposes\n",
    "print(\"numpy version: \" + np.__version__)\n",
    "print(\"pandas version: \" + pd.__version__)\n",
    "import river\n",
    "print(\"river version: \" + river.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 1 - get a data sample from Splunk\n",
    "In Splunk run a search to pipe a dataset into your notebook environment. Note: mode=stage is used in the | fit command to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "| makeresults count=5\n",
    "| streamstats count as part\n",
    "| table part\n",
    "| map search=\"| inputlookup app_usage.csv | streamstats count as t | eval Recruiting=Recruiting*(1.0+random()%100*0.01)  | eval part=$part$ | eval t=t+91*(part-1) | table t Recruiting\"\n",
    "| table t Recruiting\n",
    "| fit MLTKContainer mode=stage algo=river_halfspacetree window_size=100 n_trees=10 height=3 Recruiting into app:online_anomaly_detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After you run this search your data set sample is available as a csv inside the container to develop your model. The name is taken from the into keyword (\"barebone_model\" in the example above) or set to \"default\" if no into keyword is present. This step is intended to work with a subset of your data to create your custom model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": false,
    "name": "mltkc_stage"
   },
   "outputs": [],
   "source": [
    "# this cell is not executed from MLTK and should only be used for staging data into the notebook environment\n",
    "def stage(name):\n",
    "    with open(\"data/\"+name+\".csv\", 'r') as f:\n",
    "        df = pd.read_csv(f)\n",
    "    with open(\"data/\"+name+\".json\", 'r') as f:\n",
    "        param = json.load(f)\n",
    "    return df, param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Recruiting\n",
      "count    91.000000\n",
      "mean    229.890110\n",
      "std     244.979113\n",
      "min       7.000000\n",
      "25%      42.500000\n",
      "50%     247.000000\n",
      "75%     305.500000\n",
      "max    2168.000000\n",
      "   Recruiting\n",
      "0          33\n",
      "1          30\n",
      "2         297\n",
      "3         308\n",
      "4         305\n",
      "{'options': {'params': {'mode': 'stage', 'algo': 'river_halfspacetree'}, 'args': ['Recruiting'], 'feature_variables': ['Recruiting'], 'model_name': 'online_anomaly_detection', 'algo_name': 'MLTKContainer', 'mlspl_limits': {'handle_new_cat': 'default', 'max_distinct_cat_values': '100', 'max_distinct_cat_values_for_classifiers': '100', 'max_distinct_cat_values_for_scoring': '100', 'max_fit_time': '600', 'max_inputs': '100000', 'max_memory_usage_mb': '4000', 'max_model_size_mb': '30', 'max_score_time': '600', 'streaming_apply': 'false', 'use_sampling': 'true'}, 'kfold_cv': None}, 'feature_variables': ['Recruiting']}\n"
     ]
    }
   ],
   "source": [
    "# THIS CELL IS NOT EXPORTED - free notebook cell for testing or development purposes\n",
    "df, param = stage(\"online_anomaly_detection\")\n",
    "print(df.describe())\n",
    "print(df.head())\n",
    "print(param)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 2 - create and initialize a model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://riverml.xyz/dev/api/anomaly/HalfSpaceTrees/\n",
    "\n",
    "Parameters\n",
    "- n_trees – defaults to 10\n",
    "Number of trees to use.\n",
    "\n",
    "- height – defaults to 8\n",
    "Height of each tree. Note that a tree of height h is made up of h + 1 levels and therefore contains 2 ** (h + 1) - 1 nodes.\n",
    "\n",
    "- window_size – defaults to 250\n",
    "Number of observations to use for calculating the mass at each node in each tree.\n",
    "\n",
    "- limits (Dict[Hashable, Tuple[float, float]]) – defaults to None\n",
    "Specifies the range of each feature. By default each feature is assumed to be in range [0, 1].\n",
    "\n",
    "- seed (int) – defaults to None\n",
    "Random number seed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "deletable": false,
    "name": "mltkc_init"
   },
   "outputs": [],
   "source": [
    "# Create the random cut forest from the source data\n",
    "def init(df,param):\n",
    "    # Set model parameters\n",
    "    X = df[param['feature_variables'][0]]    \n",
    "    n_trees=10\n",
    "    height=8\n",
    "    window_size=250\n",
    "    if 'options' in param:\n",
    "        if 'params' in param['options']:\n",
    "            if 'n_trees' in param['options']['params']:\n",
    "                n_trees = int(param['options']['params']['n_trees'])\n",
    "            if 'height' in param['options']['params']:\n",
    "                height = int(param['options']['params']['height'])\n",
    "            if 'window_size' in param['options']['params']:\n",
    "                window_size = int(param['options']['params']['window_size'])\n",
    "    \n",
    "    # Create the half space tree\n",
    "    model = compose.Pipeline(\n",
    "        preprocessing.MinMaxScaler(),\n",
    "        anomaly.HalfSpaceTrees(\n",
    "            n_trees=n_trees,\n",
    "            height=height,\n",
    "            window_size=window_size,\n",
    "            seed=42)\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# THIS CELL IS NOT EXPORTED - free notebook cell for testing or development purposes\n",
    "model=init(df,param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<html><body><div class=\"pipeline\"><details class=\"estimator\"><summary><pre class=\"estimator-name\">MinMaxScaler</pre></summary><code class=\"estimator-params\">\n",
       "{'max': defaultdict(&lt;class 'river.stats.maximum.Max'&gt;, {}),\n",
       " 'min': defaultdict(&lt;class 'river.stats.minimum.Min'&gt;, {})}\n",
       "\n",
       "</code></details><details class=\"estimator\"><summary><pre class=\"estimator-name\">HalfSpaceTrees</pre></summary><code class=\"estimator-params\">\n",
       "{'_first_window': True,\n",
       " 'counter': 0,\n",
       " 'height': 8,\n",
       " 'limits': defaultdict(..., {}),\n",
       " 'n_trees': 10,\n",
       " 'rng': &lt;random.Random object at 0x562e38b0a420&gt;,\n",
       " 'seed': 42,\n",
       " 'trees': [],\n",
       " 'window_size': 250}\n",
       "\n",
       "</code></details></div></body><style>\n",
       ".estimator {\n",
       "    padding: 1em;\n",
       "    border-style: solid;\n",
       "    background: white;\n",
       "}\n",
       "\n",
       ".pipeline {\n",
       "    display: flex;\n",
       "    flex-direction: column;\n",
       "    align-items: center;\n",
       "    background: linear-gradient(#000, #000) no-repeat center / 3px 100%;\n",
       "}\n",
       "\n",
       ".union {\n",
       "    display: flex;\n",
       "    flex-direction: row;\n",
       "    align-items: center;\n",
       "    justify-content: center;\n",
       "    padding: 1em;\n",
       "    border-style: solid;\n",
       "    background: white\n",
       "}\n",
       "\n",
       "/* Vertical spacing between steps */\n",
       "\n",
       ".estimator + .estimator,\n",
       ".estimator + .union,\n",
       ".union + .estimator {\n",
       "    margin-top: 2em;\n",
       "}\n",
       "\n",
       ".union > .estimator {\n",
       "    margin-top: 0;\n",
       "}\n",
       "\n",
       "/* Spacing within a union of estimators */\n",
       "\n",
       ".union >\n",
       ".estimator + .estimator,\n",
       ".pipeline + .estimator,\n",
       ".estimator + .pipeline,\n",
       ".pipeline + .pipeline {\n",
       "    margin-left: 1em;\n",
       "}\n",
       "\n",
       "/* Typography */\n",
       ".estimator-params {\n",
       "    display: block;\n",
       "    white-space: pre-wrap;\n",
       "    font-size: 120%;\n",
       "    margin-bottom: -1em;\n",
       "}\n",
       "\n",
       ".estimator > code {\n",
       "    background-color: white !important;\n",
       "}\n",
       "\n",
       ".estimator-name {\n",
       "    display: inline;\n",
       "    margin: 0;\n",
       "    font-size: 130%;\n",
       "}\n",
       "\n",
       "/* Toggle */\n",
       "\n",
       "summary {\n",
       "    display: flex;\n",
       "    align-items:center;\n",
       "    cursor: pointer;\n",
       "}\n",
       "\n",
       "summary > div {\n",
       "    width: 100%;\n",
       "}\n",
       "</style></html>"
      ],
      "text/plain": [
       "Pipeline (\n",
       "  MinMaxScaler (),\n",
       "  HalfSpaceTrees (\n",
       "    n_trees=10\n",
       "    height=8\n",
       "    window_size=250\n",
       "    limits=defaultdict(..., {})\n",
       "    seed=42\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 3 - fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "deletable": false,
    "name": "mltkc_fit"
   },
   "outputs": [],
   "source": [
    "# train your model\n",
    "# returns a fit info json object and may modify the model object\n",
    "def fit(model,df,param):\n",
    "    X = df[param['feature_variables'][0]]\n",
    "    # init with a few warm up samples\n",
    "    for x in X[:10]:\n",
    "        model = model.learn_one({'x': x})\n",
    "    return len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91\n"
     ]
    }
   ],
   "source": [
    "# THIS CELL IS NOT EXPORTED - free notebook cell for testing or development purposes\n",
    "print(fit(model,df,param))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 4 - apply the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "deletable": false,
    "name": "mltkc_apply"
   },
   "outputs": [],
   "source": [
    "# apply your model\n",
    "# returns the calculated results\n",
    "def apply(model,df,param):\n",
    "\n",
    "    X = df[param['feature_variables'][0]]\n",
    "    Y = []\n",
    "    \n",
    "    for x in X:\n",
    "        features = {'x': x}\n",
    "        model = model.learn_one(features)\n",
    "        score = model.score_one(features)\n",
    "        Y.append(score)        \n",
    "        #print(f'Anomaly score for x={x:.3f}: {model.score_one(features):.3f}')\n",
    "\n",
    "    # save the model\n",
    "    if 'options' in param:\n",
    "        if 'model_name' in param['options']:\n",
    "            if 'params' in param['options']:\n",
    "                if 'algo' in param['options']['params']:\n",
    "                    name = param['options']['params']['algo'] + '_' + param['options']['model_name']\n",
    "                    save(model,name)\n",
    "                    #print('/apply updated and saved model with parameters ', model)\n",
    "                    \n",
    "    \n",
    "    result=pd.DataFrame({'anomaly_score':Y})\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>anomaly_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.814780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.817586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.711616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.706582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.707032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>0.698981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>0.709301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>0.709627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>0.987604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>0.929725</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>91 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    anomaly_score\n",
       "0        0.814780\n",
       "1        0.817586\n",
       "2        0.711616\n",
       "3        0.706582\n",
       "4        0.707032\n",
       "..            ...\n",
       "86       0.698981\n",
       "87       0.709301\n",
       "88       0.709627\n",
       "89       0.987604\n",
       "90       0.929725\n",
       "\n",
       "[91 rows x 1 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# THIS CELL IS NOT EXPORTED - free notebook cell for testing or development purposes\n",
    "results=apply(model,df,param)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 5 - save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "deletable": false,
    "name": "mltkc_save"
   },
   "outputs": [],
   "source": [
    "# save model to name in expected convention \"<algo_name>_<model_name>\"\n",
    "def save(model,name):\n",
    "    with open(MODEL_DIRECTORY + name + '.pkl', 'wb') as f:\n",
    "        pickle.dump(model, f)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 6 - load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "deletable": false,
    "name": "mltkc_load"
   },
   "outputs": [],
   "source": [
    "# load model from name in expected convention \"<algo_name>_<model_name>\"\n",
    "def load(name):\n",
    "    model = {}\n",
    "    with open(MODEL_DIRECTORY + name + '.pkl', 'rb') as f:\n",
    "        model = pickle.load(f)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 7 - provide a summary of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "deletable": false,
    "name": "mltkc_summary"
   },
   "outputs": [],
   "source": [
    "# return a model summary\n",
    "def summary(model=None):\n",
    "    returns = {\"version\": {\"numpy\": np.__version__, \"pandas\": pd.__version__} }\n",
    "    return returns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End of Stages\n",
    "All subsequent cells are not tagged and can be used for further freeform code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
