{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning Toolkit for Splunk - Notebook for 'Auto-Sklearn 2.0'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains an example workflow how to work with the AutoML framework 'Auto-Sklearn' (https://automl.github.io/auto-sklearn/master/index.html) with the Deep Learning Toolkit for Splunk. The example uses the 'AutoSklearn2Classifier' classifier and can be used as template to implement other functionalities, described in the docs: https://automl.github.io/auto-sklearn/master/manual.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: By default every time you save this notebook the cells are exported into a python module which is then invoked by Splunk MLTK commands like <code> | fit ... | apply ... | summary </code>. Please read the Model Development Guide in the Deep Learning Toolkit app for more information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### example SPL to create and fit sample data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| inputlookup track_day.csv</br>\n",
    "| rename * as x_*</br>\n",
    "| rename x_vehicleType as y_vehicleType</br>\n",
    "| eventstats avg(x_engineCoolantTemperature) as avg_x_engineCoolantTemperature</br>\n",
    "| eval x_engineCoolantTemperature = coalesce(x_engineCoolantTemperature, floor(avg_x_engineCoolantTemperature))</br>\n",
    "| fields y_* x_*</br>\n",
    "| sample seed=123 100 by y_vehicleType</br>\n",
    "| fit MLTKContainer algo=autosklearn_classification dataset_name=trackday_autosklearn time_left_for_this_task=30 per_run_time_limit=10 y_vehicleType from x_* into app:trackday_autosklearn_classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 0 - import libraries\n",
    "At stage 0 we define all imports necessary to run our subsequent code depending on various libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "name": "mltkc_import"
   },
   "outputs": [],
   "source": [
    "# mltkc_import\n",
    "# this definition exposes all python module imports that should be available in all subsequent commands\n",
    "import json\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "import autosklearn\n",
    "#from autosklearn.classification import AutoSklearnClassifier\n",
    "from autosklearn.experimental.askl2 import AutoSklearn2Classifier\n",
    "\n",
    "from copy import deepcopy\n",
    "import re\n",
    "\n",
    "# global constants\n",
    "MODEL_DIRECTORY = \"/srv/app/model/data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THIS CELL IS NOT EXPORTED - free notebook cell for testing purposes\n",
    "\n",
    "print(\"pandas: \" + pd.__version__)\n",
    "print(\"autosklearn: \" + autosklearn.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 1 - get a data sample from Splunk\n",
    "In Splunk run a search to pipe a dataset into your notebook environment. Note: mode=stage is used in the | fit command to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "name": "mltkc_stage"
   },
   "outputs": [],
   "source": [
    "# mltkc_stage\n",
    "# this cell is not executed from MLTK and should only be used for staging data into the notebook environment\n",
    "def stage(name):\n",
    "    with open(\"data/\"+name+\".csv\", 'r') as f:\n",
    "        df = pd.read_csv(f)\n",
    "    with open(\"data/\"+name+\".json\", 'r') as f:\n",
    "        param = json.load(f)\n",
    "    return df, param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THIS CELL IS NOT EXPORTED - free notebook cell for testing purposes\n",
    "\n",
    "df, param = stage(\"trackday_autosklearn_classifier\")\n",
    "print(df[0:5])\n",
    "print(df.shape)\n",
    "print(str(param))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 2 - create and initialize a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "name": "mltkc_init"
   },
   "outputs": [],
   "source": [
    "# mltkc_init\n",
    "# initialize the model\n",
    "# params: data and parameters\n",
    "# returns the model object which will be used as a reference to call fit, apply and summary subsequently\n",
    "def init(df,param):\n",
    "    params = deepcopy(param['options']['params'])\n",
    "    params.pop('algo', None)\n",
    "    params.pop('mode', None)\n",
    "    params.pop('dataset_name', None)\n",
    "    for key in params:\n",
    "        try:\n",
    "            if params[key].isdigit():\n",
    "                params[key] = int(params[key])\n",
    "        except:\n",
    "            pass\n",
    "    model = {}\n",
    "    model[\"model\"] = AutoSklearn2Classifier(\n",
    "        **params\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# THIS CELL IS NOT EXPORTED - free notebook cell for testing purposes\n",
    "\n",
    "df, param = stage(\"trackday_autosklearn_classifier\")\n",
    "model = init(df,param)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 3 - fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "name": "mltkc_fit"
   },
   "outputs": [],
   "source": [
    "# mltkc_stage_create_model_fit\n",
    "# returns a fit info json object\n",
    "def fit(model,df,param):\n",
    "    returns = {}\n",
    "    for col in df.select_dtypes(['object']):\n",
    "        df[col] = df[col].astype('category')\n",
    "    X = df[param['feature_variables']]\n",
    "    y = df[param['target_variables']].values\n",
    "    dsname = param['options']['params']['dataset_name'] if (\"dataset_name\" in param['options']['params']) else None\n",
    "    returns['dataset_name'] = dsname\n",
    "    returns['fit_history'] = model[\"model\"].fit(X, y, dataset_name=dsname)\n",
    "    return returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THIS CELL IS NOT EXPORTED - free notebook cell for testing purposes\n",
    "\n",
    "print(fit(model,df,param))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 4 - apply the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "name": "mltkc_apply"
   },
   "outputs": [],
   "source": [
    "# mltkc_stage_create_model_apply\n",
    "def apply(model,df,param):\n",
    "    for col in df.select_dtypes(['object']):\n",
    "        df[col] = df[col].astype('category')\n",
    "    X = df[param['feature_variables']]\n",
    "    y_hat = model[\"model\"].predict(X)\n",
    "    return y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THIS CELL IS NOT EXPORTED - free notebook cell for testing purposes\n",
    "\n",
    "df, param = stage(\"trackday_autosklearn_classifier\")\n",
    "print(apply(model,df,param))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 5 - save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "name": "mltkc_save"
   },
   "outputs": [],
   "source": [
    "# save model to name in expected convention \"<algo_name>_<model_name>.h5\"\n",
    "def save(model,name):\n",
    "    model[\"summary\"] = {}\n",
    "    model[\"summary\"][\"statistics\"] = {}\n",
    "    for s in model[\"model\"].sprint_statistics().split(\"\\n\")[1:-1]:\n",
    "        match = re.search('(.*):\\s(.*)', s.strip(), re.IGNORECASE)\n",
    "        if match:\n",
    "            model[\"summary\"][\"statistics\"][match.group(1)] = str(match.group(2))\n",
    "\n",
    "    cv_result_keys = {'mean_test_score': 1, 'mean_fit_time': 1, 'status': 0, 'rank_test_scores': 1}\n",
    "    for k,v in cv_result_keys.items():\n",
    "        model[\"summary\"][k] = str(model[\"model\"].cv_results_[k].tolist()) if (v) else model[\"model\"].cv_results_[k]\n",
    "\n",
    "    model[\"summary\"][\"models\"] = []\n",
    "    models_ww = model[\"model\"].get_models_with_weights()\n",
    "    p = re.compile('(?<!\\\\\\\\)\\'')\n",
    "    for m in models_ww:\n",
    "        curr_weight = m[0]\n",
    "        curr_model = p.sub('\\\"', re.search('.*\\((\\{.*\\})', str(m[1]), re.IGNORECASE).group(1))\n",
    "        model_json = json.loads(curr_model)\n",
    "        model_json[\"weight\"] = curr_weight\n",
    "        model[\"summary\"][\"models\"].append(model_json)\n",
    "    pickle.dump(model, open(MODEL_DIRECTORY + name + \".pickle\", 'wb'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THIS CELL IS NOT EXPORTED - free notebook cell for testing purposes\n",
    "\n",
    "save(model,\"trackday_autosklearn_classifier\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 6 - load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "name": "mltkc_load"
   },
   "outputs": [],
   "source": [
    "# load model from name in expected convention \"<algo_name>_<model_name>.h5\"\n",
    "def load(name):\n",
    "    with open(MODEL_DIRECTORY + name + \".pickle\", 'rb') as pickle_file:\n",
    "        model = pickle.load(pickle_file)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THIS CELL IS NOT EXPORTED - free notebook cell for testing purposes\n",
    "\n",
    "model = load(\"trackday_autosklearn_classifier\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 7 - provide a summary of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "name": "mltkc_summary"
   },
   "outputs": [],
   "source": [
    "# return model summary\n",
    "def summary(model=None):\n",
    "    returns = {\"version\": {\"autosklearn\": autosklearn.__version__} }\n",
    "    return returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THIS CELL IS NOT EXPORTED - free notebook cell for testing purposes\n",
    "\n",
    "summary(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End of Stages\n",
    "All subsequent cells are not tagged and can be used for further freeform code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
