{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Query Milvus"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 0 - import libraries\n",
    "At stage 0 we define all imports necessary to run our subsequent code depending on various libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "name": "mltkc_import",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# this definition exposes all python module imports that should be available in all subsequent commands\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "import time\n",
    "\n",
    "import pymilvus\n",
    "\n",
    "from pymilvus import (\n",
    "    connections,\n",
    "    utility,\n",
    "    FieldSchema, CollectionSchema, DataType,\n",
    "    Collection,\n",
    ")\n",
    "\n",
    "# ...\n",
    "# global constants\n",
    "MODEL_DIRECTORY = \"/srv/app/model/data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numpy version: 1.23.5\n",
      "pandas version: 2.0.2\n",
      "pymilvus version: 2.2.9\n"
     ]
    }
   ],
   "source": [
    "# THIS CELL IS NOT EXPORTED - free notebook cell for testing or development purposes\n",
    "print(\"numpy version: \" + np.__version__)\n",
    "print(\"pandas version: \" + pd.__version__)\n",
    "print(\"pymilvus version: \" + pymilvus.__version__)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 2 - push data from Splunk\n",
    "In Splunk run a search to pipe a dataset into your notebook environment. You utilize the `mode=stage` flag in the in the `| fit` command to do this. The search results are accessible then as csv file with the same model name that is defined in the `into app:<modelname>` part of the fit statement. Additionally, meta data is retrieved and accessible as json file. In the same way you can further work with the meta data object as it is exposed in the fit and apply function definitions below in stage 3 and 4."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| makeresults count=10<br>\n",
    "| streamstats c as i <br>\n",
    "| eval s = i%3 <br>\n",
    "| eval feature_{s}=0 <br>\n",
    "| foreach feature_* [eval \\<\\<FIELD\\>\\>=random()/pow(2,31)]<br>\n",
    "| fit MLTKContainer mode=stage algo=barebone_template _time feature_* i into app:barebone_template<br>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After you run this search your data set sample is available as a csv inside the container to develop your model. The name is taken from the into keyword (\"barebone_model\" in the example above) or set to \"default\" if no into keyword is present. This step is intended to work with a subset of your data to create your custom model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": false,
    "name": "mltkc_stage",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# this cell is not executed from MLTK and should only be used for staging data into the notebook environment\n",
    "def stage(name):\n",
    "    with open(\"data/\"+name+\".csv\", 'r') as f:\n",
    "        df = pd.read_csv(f)\n",
    "    with open(\"data/\"+name+\".json\", 'r') as f:\n",
    "        param = json.load(f)\n",
    "    return df, param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# THIS CELL IS NOT EXPORTED - free notebook cell for testing or development purposes\n",
    "df, param = stage(\"query_milvus\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vector_1</th>\n",
       "      <th>vector_2</th>\n",
       "      <th>vector_3</th>\n",
       "      <th>vector_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.702</td>\n",
       "      <td>0.117</td>\n",
       "      <td>0.571</td>\n",
       "      <td>0.552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.588</td>\n",
       "      <td>0.696</td>\n",
       "      <td>0.511</td>\n",
       "      <td>0.925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.325</td>\n",
       "      <td>0.067</td>\n",
       "      <td>0.410</td>\n",
       "      <td>0.379</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   vector_1  vector_2  vector_3  vector_4\n",
       "0     0.702     0.117     0.571     0.552\n",
       "1     0.588     0.696     0.511     0.925\n",
       "2     0.325     0.067     0.410     0.379"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'options': {'params': {'mode': 'stage',\n",
       "   'algo': 'query_milvus',\n",
       "   'collection_name': 'new_collection',\n",
       "   'n_dims': '4'},\n",
       "  'args': ['vector_*'],\n",
       "  'feature_variables': ['vector_*'],\n",
       "  'model_name': 'query_milvus',\n",
       "  'algo_name': 'MLTKContainer',\n",
       "  'mlspl_limits': {'handle_new_cat': 'default',\n",
       "   'max_distinct_cat_values': '100',\n",
       "   'max_distinct_cat_values_for_classifiers': '100',\n",
       "   'max_distinct_cat_values_for_scoring': '100',\n",
       "   'max_fit_time': '600',\n",
       "   'max_inputs': '100000',\n",
       "   'max_memory_usage_mb': '4000',\n",
       "   'max_model_size_mb': '30',\n",
       "   'max_score_time': '600',\n",
       "   'use_sampling': 'true'},\n",
       "  'kfold_cv': None},\n",
       " 'feature_variables': ['vector_1', 'vector_2', 'vector_3', 'vector_4']}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 2 - create and initialize a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "deletable": false,
    "name": "mltkc_init",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# initialize your model\n",
    "# available inputs: data and parameters\n",
    "# returns the model object which will be used as a reference to call fit, apply and summary subsequently\n",
    "def init(df,param):\n",
    "    model = {}\n",
    "        \n",
    "    pk_type=DataType.VARCHAR        \n",
    "    embedding_type=DataType.FLOAT_VECTOR\n",
    "    \n",
    "    try:\n",
    "        collection_name=param['options']['params']['collection_name']\n",
    "    except:\n",
    "        collection_name=\"default_collection\"\n",
    "    \n",
    "    print(\"start connecting to Milvus\")\n",
    "    # this hostname may need changing to a specific local docker network ip address depending on docker configuration\n",
    "    connections.connect(\"default\", host=\"milvus-standalone\", port=\"19530\")\n",
    "\n",
    "    collection_exists = utility.has_collection(collection_name)\n",
    "    \n",
    "    if collection_exists:\n",
    "        print(f\"The collection {collection_name} already exists\")\n",
    "        collection = Collection(collection_name)\n",
    "        collection.load()\n",
    "    else:\n",
    "        print(f\"The collection {collection_name} does not exist\")\n",
    "        raise Exception(\"The collection {collection_name} does not exist. Create it by sending data to a collection with that name using the push_to_milvus algo.\")\n",
    "    \n",
    "    model['collection']=collection\n",
    "    model['collection_name']=collection_name\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start connecting to Milvus\n",
      "The collection new_collection already exists\n",
      "{'collection': <Collection>:\n",
      "-------------\n",
      "<name>: new_collection\n",
      "<description>: dsdl schema for new_collection\n",
      "<schema>: {'auto_id': True, 'description': 'dsdl schema for new_collection', 'fields': [{'name': '_key', 'description': '', 'type': <DataType.INT64: 5>, 'is_primary': True, 'auto_id': True}, {'name': 'embeddings', 'description': '', 'type': <DataType.FLOAT_VECTOR: 101>, 'params': {'dim': 4}}, {'name': 'label', 'description': '', 'type': <DataType.VARCHAR: 21>, 'params': {'max_length': 1000}}]}\n",
      ", 'collection_name': 'new_collection'}\n"
     ]
    }
   ],
   "source": [
    "# THIS CELL IS NOT EXPORTED - free notebook cell for testing or development purposes\n",
    "model = init(df,param)\n",
    "print(model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 3 - fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "deletable": false,
    "name": "mltkc_fit",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train your model\n",
    "# returns a fit info json object and may modify the model object\n",
    "def fit(model,df,param):\n",
    "    try:\n",
    "        n_neighbours=int(param['options']['params']['n_neighbours'])\n",
    "    except:\n",
    "        n_neighbours=3\n",
    "        \n",
    "    try:\n",
    "        splitter=int(param['options']['params']['splitter'])\n",
    "    except:\n",
    "        splitter=\"|\"\n",
    "    \n",
    "    vectors_to_search = df.values.tolist()\n",
    "    \n",
    "    search_params = {\n",
    "        \"metric_type\": \"L2\",\n",
    "        \"params\": {\"nprobe\": 10},\n",
    "    }\n",
    "    \n",
    "    result = pd.DataFrame(model['collection'].search(vectors_to_search, \"embeddings\", search_params, limit=n_neighbours, output_fields=[\"_key\",\"label\"]))\n",
    "    \n",
    "    def expand_hits(element):\n",
    "        label=element.entity.get('label')\n",
    "        #distance=element.distance\n",
    "        return label\n",
    "    \n",
    "    result=result.applymap(expand_hits).astype(str)\n",
    "    result=pd.DataFrame(result.apply(lambda row: f'{splitter}'.join(row.values), axis=1))\n",
    "    \n",
    "    result.columns=['neighbours']\n",
    "    \n",
    "    model['result']=result\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  neighbours\n",
      "0      2|8|2\n",
      "1      6|2|3\n",
      "2      0|0|0\n"
     ]
    }
   ],
   "source": [
    "# THIS CELL IS NOT EXPORTED - free notebook cell for testing or development purposes\n",
    "print(fit(model,df,param))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 4 - apply the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "deletable": false,
    "name": "mltkc_apply",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# apply your model\n",
    "# returns the calculated results\n",
    "def apply(model,df,param):\n",
    "    return model['result']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  neighbours\n",
      "0      2,0,3\n",
      "1      3,7,0\n",
      "2      0,1,6\n"
     ]
    }
   ],
   "source": [
    "# THIS CELL IS NOT EXPORTED - free notebook cell for testing or development purposes\n",
    "print(apply(model,df,param))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 7 - provide a summary of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "deletable": false,
    "name": "mltkc_summary"
   },
   "outputs": [],
   "source": [
    "# return a model summary\n",
    "def summary(model=None):\n",
    "    returns = {\"version\": {\"numpy\": np.__version__, \"pandas\": pd.__version__} }\n",
    "    return returns"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
